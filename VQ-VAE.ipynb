{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a9342e8",
   "metadata": {},
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1bde84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 32, 2, 721, 1440])\n",
      "torch.Size([1, 32, 2, 721, 1440])\n",
      "torch.Size([1, 32, 2, 722, 1441]) after pad\n",
      "torch.Size([1, 32, 2, 361, 721])\n",
      "torch.Size([1, 32, 2, 362, 722]) after pad\n",
      "torch.Size([1, 32, 2, 181, 361])\n",
      "torch.Size([1, 64, 2, 181, 361])\n",
      "Output shape: torch.Size([1, 64, 2, 181, 360])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from VQGAN.helper import ResidualBlock, NonLocalBlock, DownSampleBlock, GroupNorm, Swish\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super(Encoder, self).__init__()\n",
    "        channels = [32, 32, 32, 64, 64]\n",
    "        attn_resolutions = [2]\n",
    "        num_res_blocks = 1\n",
    "        resolution = 256\n",
    "\n",
    "        # 初始卷积层\n",
    "        self.conv_in = nn.Conv3d(args.image_channels, channels[0], kernel_size=(1, 3, 3), stride=1, padding=(0, 1, 1)) #改变最初的kernal size即可改变T维度的缩放\n",
    "        \n",
    "        # 第一层（含残差块和注意力模块）\n",
    "        self.layer1 = self._make_layer(channels[0], channels[1], num_res_blocks, resolution, attn_resolutions)\n",
    "        \n",
    "        # 下采样与第二层\n",
    "        self.downsample1 = DownSampleBlock(channels[1])\n",
    "        self.layer2 = self._make_layer(channels[1], channels[2], num_res_blocks, resolution // 2, attn_resolutions)\n",
    "\n",
    "        # Further downsampling and third layer\n",
    "        self.downsample2 = DownSampleBlock(channels[2])\n",
    "        self.layer3 = self._make_layer(channels[2], channels[3], num_res_blocks, resolution // 4, attn_resolutions)\n",
    "\n",
    "        # 中间层的残差块和注意力模块\n",
    "        self.mid_block1 = ResidualBlock(channels[3], channels[3])\n",
    "        #self.mid_attn = NonLocalBlock(channels[3])\n",
    "        self.mid_block2 = ResidualBlock(channels[3], channels[3])\n",
    "        \n",
    "        # 输出层的归一化、激活和最终卷积层\n",
    "        self.norm_out = GroupNorm(channels[3])\n",
    "        self.act_out = Swish()\n",
    "        self.conv_out = nn.Conv3d(channels[3], args.latent_dim, kernel_size=3, stride=1, padding=(1,2,1))\n",
    "\n",
    "    def _make_layer(self, in_channels, out_channels, num_res_blocks, resolution, attn_resolutions):\n",
    "        layers = []\n",
    "        for _ in range(num_res_blocks):\n",
    "            layers.append(ResidualBlock(in_channels, out_channels))\n",
    "            in_channels = out_channels\n",
    "            if resolution in attn_resolutions:\n",
    "                layers.append(NonLocalBlock(in_channels))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 初始卷积\n",
    "        x = self.conv_in(x)\n",
    "        print(x.shape)\n",
    "        # 第一层，并存储跳跃连接\n",
    "        x = self.layer1(x)\n",
    "        skip = x  # 保存第一层输出，用于后续跳跃连接\n",
    "        print(x.shape)\n",
    "        # 下采样，进入第二层\n",
    "        x = self.downsample1(x)\n",
    "        x = self.layer2(x)\n",
    "        print(x.shape)\n",
    "        # Further downsample and third layer\n",
    "        x = self.downsample2(x)\n",
    "        print(x.shape)\n",
    "        x = self.layer3(x)\n",
    "        print(x.shape)\n",
    "        # 中间层的残差块和注意力模块\n",
    "        x = self.mid_block1(x)\n",
    "        #x = self.mid_attn(x)\n",
    "        x = self.mid_block2(x)\n",
    "        \n",
    "        # 最终的归一化、激活和卷积输出层\n",
    "        x = self.norm_out(x)\n",
    "        x = self.act_out(x)\n",
    "        x = self.conv_out(x)[:, :, :, :181, :360]\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "class Args:\n",
    "    image_channels = 14  # RGB image channels\n",
    "    latent_dim = 64     # Set a latent dimension for the output\n",
    "\n",
    "# Instantiate Args and Encoder\n",
    "args = Args()\n",
    "encoder = Encoder(args)\n",
    "\n",
    "# Create a random input tensor (batch size of 1, RGB image with resolution 256x256)\n",
    "input_tensor = torch.randn(1, Args.image_channels, 2, 721, 1440).cuda()\n",
    "#input_tensor = torch.randn(1, Args.image_channels, 2, 721, 1440).cuda()\n",
    "model = encoder.cuda()\n",
    "\n",
    "# Forward pass through the encoder\n",
    "output = model(input_tensor)\n",
    "\n",
    "# Print the output shape\n",
    "print(\"Output shape:\", output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59f73b9",
   "metadata": {},
   "source": [
    "## Encoder 4D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57c9359d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 32, 4, 2, 721, 1440])\n",
      "torch.Size([1, 32, 4, 2, 721, 1440])\n",
      "torch.Size([1, 32, 4, 2, 722, 1441]) after pad\n",
      "torch.Size([1, 32, 4, 2, 361, 721])\n",
      "torch.Size([1, 32, 4, 2, 362, 722]) after pad\n",
      "torch.Size([1, 32, 4, 2, 181, 361])\n",
      "torch.Size([1, 64, 4, 2, 181, 361])\n",
      "Output shape: torch.Size([1, 64, 2, 2, 181, 360])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from VQGAN.helper import ResidualBlock, NonLocalBlock, DownSampleBlock, GroupNorm, Swish, ResidualBlock4D, DownSampleBlock4D\n",
    "from VQGAN.conv import Conv4d\n",
    "\n",
    "class Encoder4D(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super(Encoder4D, self).__init__()\n",
    "        channels = [32, 32, 32, 64, 64]\n",
    "        attn_resolutions = [2]\n",
    "        num_res_blocks = 1\n",
    "        resolution = 256\n",
    "\n",
    "        # 初始卷积层\n",
    "        self.conv_in = Conv4d(args.image_channels, channels[0], kernel_size=(1, 1, 3, 3), stride=1, padding=(0, 0, 1, 1))\n",
    "        \n",
    "        # 第一层（含残差块和注意力模块）\n",
    "        self.layer1 = self._make_layer(channels[0], channels[1], num_res_blocks, resolution, attn_resolutions)\n",
    "        \n",
    "        # 下采样与第二层\n",
    "        self.downsample1 = DownSampleBlock4D(channels[1])\n",
    "        self.layer2 = self._make_layer(channels[1], channels[2], num_res_blocks, resolution // 2, attn_resolutions)\n",
    "\n",
    "        # Further downsampling and third layer\n",
    "        self.downsample2 = DownSampleBlock4D(channels[2])\n",
    "        self.layer3 = self._make_layer(channels[2], channels[3], num_res_blocks, resolution // 4, attn_resolutions)\n",
    "\n",
    "        # 中间层的残差块和注意力模块\n",
    "        self.mid_block1 = ResidualBlock4D(channels[3], channels[3])\n",
    "        #self.mid_attn = NonLocalBlock(channels[3])\n",
    "        self.mid_block2 = ResidualBlock4D(channels[3], channels[3])\n",
    "        \n",
    "        # 输出层的归一化、激活和最终卷积层\n",
    "        self.norm_out = GroupNorm(channels[3])\n",
    "        self.act_out = Swish()\n",
    "        self.conv_out = Conv4d(channels[3], args.latent_dim, kernel_size=(2, 1, 3, 3), stride=(2, 1, 1, 1), padding=(0,0,1,1))\n",
    "\n",
    "    def _make_layer(self, in_channels, out_channels, num_res_blocks, resolution, attn_resolutions):\n",
    "        layers = []\n",
    "        for _ in range(num_res_blocks):\n",
    "            layers.append(ResidualBlock4D(in_channels, out_channels))\n",
    "            in_channels = out_channels\n",
    "            if resolution in attn_resolutions:\n",
    "                layers.append(NonLocalBlock(in_channels))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 初始卷积\n",
    "        x = self.conv_in(x)\n",
    "        print(x.shape)\n",
    "        # 第一层，并存储跳跃连接\n",
    "        x = self.layer1(x)\n",
    "        skip = x  # 保存第一层输出，用于后续跳跃连接\n",
    "        print(x.shape)\n",
    "        # 下采样，进入第二层\n",
    "        x = self.downsample1(x)\n",
    "        x = self.layer2(x)\n",
    "        print(x.shape)\n",
    "        # Further downsample and third layer\n",
    "        x = self.downsample2(x)\n",
    "        print(x.shape)\n",
    "        x = self.layer3(x)\n",
    "        print(x.shape)\n",
    "        # 中间层的残差块和注意力模块\n",
    "        x = self.mid_block1(x)\n",
    "        #x = self.mid_attn(x)\n",
    "        x = self.mid_block2(x)\n",
    "        \n",
    "        # 最终的归一化、激活和卷积输出层\n",
    "        x = self.norm_out(x)\n",
    "        x = self.act_out(x)\n",
    "        x = self.conv_out(x)[:, :, :, :, :181, :360]\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "class Args:\n",
    "    image_channels = 7  # RGB image channels\n",
    "    latent_dim = 64     # Set a latent dimension for the output\n",
    "\n",
    "# Instantiate Args and Encoder\n",
    "args = Args()\n",
    "encoder = Encoder4D(args)\n",
    "\n",
    "# Create a random input tensor (batch size of 1, RGB image with resolution 256x256)\n",
    "input_tensor = torch.randn(1, Args.image_channels, 4, 2, 721, 1440).cuda()\n",
    "#input_tensor = torch.randn(1, Args.image_channels, 2, 721, 1440).cuda()\n",
    "model = encoder.cuda()\n",
    "\n",
    "# Forward pass through the encoder\n",
    "output = model(input_tensor)\n",
    "\n",
    "# Print the output shape\n",
    "print(\"Output shape:\", output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1febcf98",
   "metadata": {},
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948f948f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 2, 181, 360]) before inter\n",
      "torch.Size([1, 64, 2, 362, 720])\n",
      "torch.Size([1, 32, 2, 362, 720]) before inter\n",
      "torch.Size([1, 32, 2, 724, 1440])\n",
      "torch.Size([1, 32, 2, 724, 1440])\n",
      "decoder shape: torch.Size([1, 14, 2, 721, 1440])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from VQGAN.helper import ResidualBlock, NonLocalBlock, UpSampleBlock, GroupNorm, Swish\n",
    "\n",
    "\n",
    "# 定义 Decoder 类（略去细节，假设已实现）\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super(Decoder, self).__init__()\n",
    "        channels = [64, 64, 32, 32]  # Decoder 的通道配置\n",
    "        num_res_blocks = 1  # 与 Encoder 对齐\n",
    "\n",
    "        # 初始卷积层\n",
    "        self.conv_in = nn.Conv3d(args.latent_dim, channels[0], kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        # 第一层残差块\n",
    "        self.layer1 = self._make_layer(channels[0], channels[1], num_res_blocks)\n",
    "        \n",
    "        # 上采样和第二层残差块\n",
    "        self.upsample1 = UpSampleBlock(channels[1])\n",
    "        self.layer2 = self._make_layer(channels[1], channels[2], num_res_blocks)\n",
    "\n",
    "        self.upsample2 = UpSampleBlock(channels[2])\n",
    "        self.layer3 = self._make_layer(channels[2], channels[3], num_res_blocks)\n",
    "        \n",
    "        # 中间层的残差块\n",
    "        self.mid_block1 = ResidualBlock(channels[3], channels[3])\n",
    "        self.mid_block2 = ResidualBlock(channels[3], channels[3])\n",
    "        \n",
    "        # 最终输出层\n",
    "        self.norm_out = GroupNorm(channels[3])\n",
    "        self.act_out = Swish()\n",
    "        self.conv_out = nn.Conv3d(channels[3], args.image_channels, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
    "\n",
    "    def _make_layer(self, in_channels, out_channels, num_res_blocks):\n",
    "        # 创建指定数量的残差块\n",
    "        layers = [ResidualBlock(in_channels, out_channels) for _ in range(num_res_blocks)]\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 初始卷积\n",
    "        x = self.conv_in(x)\n",
    "\n",
    "        # 第一层残差块\n",
    "        x = self.layer1(x)\n",
    "\n",
    "        # 上采样和第二层残差块\n",
    "        x = self.upsample1(x)  # 上采样后通道数保持不变\n",
    "        print(x.shape)\n",
    "        x = self.layer2(x)     # 确保输入与 layer2 的期望通道数匹配\n",
    "\n",
    "        x = self.upsample2(x)  # 上采样后通道数保持不变\n",
    "        print(x.shape)\n",
    "        x = self.layer3(x)     # 确保输入与 layer2 的期望通道数匹配\n",
    "        \n",
    "        # 中间层的残差块\n",
    "        x = self.mid_block1(x)\n",
    "        x = self.mid_block2(x)\n",
    "        \n",
    "        # 最终的归一化、激活和卷积输出层\n",
    "        x = self.norm_out(x)\n",
    "        x = self.act_out(x)\n",
    "        print(x.shape)\n",
    "        x = self.conv_out(x)[:, :, :, :721, :1440]\n",
    "        \n",
    "        return x\n",
    "    \n",
    "# 创建实例\n",
    "\n",
    "class Args:\n",
    "    image_channels = 14   # 输入图像的通道数（例如 RGB 图像为 3）\n",
    "    latent_dim = 64      # 潜在空间的通道数\n",
    "    num_codebook_vectors = 512\n",
    "    beta = 0.25\n",
    "args = Args()\n",
    "decoder = Decoder(args).cuda()\n",
    "\n",
    "# 输入张量\n",
    "input_tensor = torch.randn(1, 64, 2, 181, 360).cuda()\n",
    "\n",
    "# 编码过程\n",
    "decoder = decoder(input_tensor)\n",
    "print(\"decoder shape:\", decoder.shape)  # 期望输出: torch.Size([1, 64, 360, 720])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877e2dcf",
   "metadata": {},
   "source": [
    "## Decoder4D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aae3f9b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 4, 2, 362, 720])\n",
      "torch.Size([1, 32, 4, 2, 724, 1440])\n",
      "torch.Size([1, 32, 4, 2, 724, 1440])\n",
      "decoder shape: torch.Size([1, 14, 4, 2, 724, 1440])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from VQGAN.helper import ResidualBlock, NonLocalBlock, UpSampleBlock, GroupNorm, Swish, UpSampleBlock4D, ResidualBlock4D\n",
    "from VQGAN.conv import ConvTranspose4d\n",
    "from VQGAN.conv import Conv4d\n",
    "\n",
    "# 定义 Decoder 类（略去细节，假设已实现）\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super(Decoder, self).__init__()\n",
    "        channels = [64, 64, 32, 32]  # Decoder 的通道配置\n",
    "        num_res_blocks = 1  # 与 Encoder 对齐\n",
    "\n",
    "        # 初始卷积层\n",
    "        self.conv_in = Conv4d(args.latent_dim, channels[0], kernel_size=(1, 1, 3, 3), stride=1, padding=(0, 0, 1, 1))\n",
    "        \n",
    "        # 第一层残差块\n",
    "        self.layer1 = self._make_layer(channels[0], channels[1], num_res_blocks)\n",
    "        \n",
    "        # 上采样和第二层残差块\n",
    "        #self.upsample1 = UpSampleBlock4D(channels[1])\n",
    "        self.upsample1 = ConvTranspose4d(channels[1], channels[1], kernel_size=(2, 1, 2, 2), stride=(2, 1, 2, 2),padding=(0, 0, 0, 0))\n",
    "        self.layer2 = self._make_layer(channels[1], channels[2], num_res_blocks)\n",
    "\n",
    "        #self.upsample2 = UpSampleBlock4D(channels[2])\n",
    "        self.upsample2 = ConvTranspose4d(channels[2], channels[2], kernel_size=(1, 1, 2, 2), stride=(1, 1, 2, 2),padding=(0, 0, 0, 0))\n",
    "        self.layer3 = self._make_layer(channels[2], channels[3], num_res_blocks)\n",
    "        \n",
    "        # 中间层的残差块\n",
    "        self.mid_block1 = ResidualBlock4D(channels[3], channels[3])\n",
    "        self.mid_block2 = ResidualBlock4D(channels[3], channels[3])\n",
    "        \n",
    "        # 最终输出层\n",
    "        self.norm_out = GroupNorm(channels[3])\n",
    "        self.act_out = Swish()\n",
    "        self.conv_out = Conv4d(channels[3], args.image_channels, kernel_size=(1, 1, 3, 3), stride=1, padding=(0, 0, 1, 1))\n",
    "\n",
    "    def _make_layer(self, in_channels, out_channels, num_res_blocks):\n",
    "        # 创建指定数量的残差块\n",
    "        layers = [ResidualBlock4D(in_channels, out_channels) for _ in range(num_res_blocks)]\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 初始卷积\n",
    "        x = self.conv_in(x)\n",
    "\n",
    "        # 第一层残差块\n",
    "        x = self.layer1(x)\n",
    "\n",
    "        # 上采样和第二层残差块\n",
    "        x = self.upsample1(x)  # 上采样后通道数保持不变\n",
    "        print(x.shape)\n",
    "        x = self.layer2(x)     # 确保输入与 layer2 的期望通道数匹配\n",
    "\n",
    "        x = self.upsample2(x)  # 上采样后通道数保持不变\n",
    "        print(x.shape)\n",
    "        x = self.layer3(x)     # 确保输入与 layer2 的期望通道数匹配\n",
    "        \n",
    "        # 中间层的残差块\n",
    "        x = self.mid_block1(x)\n",
    "        x = self.mid_block2(x)\n",
    "        \n",
    "        # 最终的归一化、激活和卷积输出层\n",
    "        x = self.norm_out(x)\n",
    "        x = self.act_out(x)\n",
    "        print(x.shape)\n",
    "        x = self.conv_out(x)[:, :, :, :721, :1440]\n",
    "        \n",
    "        return x\n",
    "    \n",
    "# 创建实例\n",
    "\n",
    "class Args:\n",
    "    image_channels = 14   # 输入图像的通道数（例如 RGB 图像为 3）\n",
    "    latent_dim = 64      # 潜在空间的通道数\n",
    "    num_codebook_vectors = 512\n",
    "    beta = 0.25\n",
    "args = Args()\n",
    "decoder = Decoder(args).cuda()\n",
    "\n",
    "# 输入张量\n",
    "input_tensor = torch.randn(1, 64, 2, 2, 181, 360).cuda()\n",
    "\n",
    "# 编码过程\n",
    "decoder = decoder(input_tensor)\n",
    "print(\"decoder shape:\", decoder.shape)  # 期望输出: torch.Size([1, 64, 360, 720])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31dc90f1",
   "metadata": {},
   "source": [
    "## Codebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e00ecec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "离散的潜在表示 z_q 的形状: torch.Size([1, 192, 181, 360])\n",
      "编码索引的形状: torch.Size([195480])\n",
      "量化损失: 1.2486979961395264\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class Codebook(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super(Codebook, self).__init__()\n",
    "        self.num_codebook_vectors = args.num_codebook_vectors\n",
    "        self.latent_dim = args.latent_dim\n",
    "        self.beta = args.beta\n",
    "\n",
    "        self.embedding = nn.Embedding(self.num_codebook_vectors, self.latent_dim)\n",
    "        self.embedding.weight.data.uniform_(-1.0 / self.num_codebook_vectors, 1.0 / self.num_codebook_vectors)\n",
    "\n",
    "    def forward(self, z):\n",
    "        z = z.view(z.size(0), -1, z.size(3), z.size(4))\n",
    "        z = z.permute(0, 2, 3, 1).contiguous()\n",
    "        z_flattened = z.view(-1, self.latent_dim)\n",
    "\n",
    "        d = torch.sum(z_flattened**2, dim=1, keepdim=True) + \\\n",
    "            torch.sum(self.embedding.weight**2, dim=1) - \\\n",
    "            2*(torch.matmul(z_flattened, self.embedding.weight.t()))\n",
    "\n",
    "        min_encoding_indices = torch.argmin(d, dim=1)\n",
    "        z_q = self.embedding(min_encoding_indices).view(z.shape)\n",
    "\n",
    "        loss = torch.mean((z_q.detach() - z)**2) + self.beta * torch.mean((z_q - z.detach())**2)\n",
    "\n",
    "        z_q = z + (z_q - z).detach()\n",
    "\n",
    "        z_q = z_q.permute(0, 3, 1, 2)\n",
    "\n",
    "        return z_q, min_encoding_indices, loss\n",
    "    \n",
    "class Args:\n",
    "    num_codebook_vectors = 512  # 代码本中向量的数量\n",
    "    latent_dim = 64  # 潜在空间的维度\n",
    "    beta = 0.25  # 损失中的 beta 参数\n",
    "\n",
    "args = Args()\n",
    "\n",
    "# 创建 Codebook 实例\n",
    "codebook = Codebook(args).cuda()\n",
    "\n",
    "# 创建输入张量，形状为 [1, 64, 360, 720]\n",
    "input_tensor = torch.randn(1, 2, 96, 181, 360).cuda()\n",
    "\n",
    "# 前向传播\n",
    "z_q, min_encoding_indices, q_loss = codebook(input_tensor)\n",
    "print(\"离散的潜在表示 z_q 的形状:\", z_q.shape)\n",
    "print(\"编码索引的形状:\", min_encoding_indices.shape)\n",
    "print(\"量化损失:\", q_loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4044da2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: torch.Size([1, 2, 96, 181, 360])\n",
      "Reshaped shape: torch.Size([1, 192, 181, 360])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 创建一个随机张量\n",
    "x = torch.randn(1, 2, 96, 181, 360).cuda()\n",
    "\n",
    "# 调整维度，合并第二维和第三维\n",
    "x_reshaped = x.view(x.size(0), -1, x.size(3), x.size(4))\n",
    "\n",
    "# 打印结果维度\n",
    "print(\"Original shape:\", x.shape)\n",
    "print(\"Reshaped shape:\", x_reshaped.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a5dc1cf8-1c45-45a0-8c50-6f6e964b032a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from VQGAN.helper import ResidualBlock, NonLocalBlock, DownSampleBlock, UpSampleBlock, GroupNorm, Swish\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super(Encoder, self).__init__()\n",
    "        channels = [128, 128, 128, 256, 256, 512]\n",
    "        attn_resolutions = [2]\n",
    "        num_res_blocks = 1\n",
    "        resolution = 256\n",
    "        layers = [nn.Conv2d(args.image_channels, channels[0], 3, 1, 1)]\n",
    "        for i in range(len(channels)-1):\n",
    "            in_channels = channels[i]\n",
    "            out_channels = channels[i + 1]\n",
    "            for j in range(num_res_blocks):\n",
    "                layers.append(ResidualBlock(in_channels, out_channels))\n",
    "                in_channels = out_channels\n",
    "                if resolution in attn_resolutions:\n",
    "                    layers.append(NonLocalBlock(in_channels))\n",
    "            if i != len(channels)-2:\n",
    "                layers.append(DownSampleBlock(channels[i+1]))\n",
    "                resolution //= 2\n",
    "        layers.append(ResidualBlock(channels[-1], channels[-1]))\n",
    "        layers.append(NonLocalBlock(channels[-1]))\n",
    "        layers.append(ResidualBlock(channels[-1], channels[-1]))\n",
    "        layers.append(GroupNorm(channels[-1]))\n",
    "        layers.append(Swish())\n",
    "        layers.append(nn.Conv2d(channels[-1], args.latent_dim, 3, 1, 1))\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "38a81566-48ed-4c29-9f06-bb3357695b0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([1, 64, 45, 90])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "class Args:\n",
    "    image_channels = 14  # RGB image channels\n",
    "    latent_dim = 64     # Set a latent dimension for the output\n",
    "\n",
    "# Instantiate Args and Encoder\n",
    "args = Args()\n",
    "encoder = Encoder(args)\n",
    "\n",
    "# Create a random input tensor (batch size of 1, RGB image with resolution 256x256)\n",
    "input_tensor = torch.randn(1, Args.image_channels, 721, 1440)\n",
    "\n",
    "# Forward pass through the encoder\n",
    "output = encoder(input_tensor)\n",
    "\n",
    "# Print the output shape\n",
    "print(\"Output shape:\", output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a12a86-78be-4ffe-be98-1c982cc4f148",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
